# AI MCP Toolkit Environment Configuration
# Copy this file to .env and customize as needed

# ============================================
# Server Configuration
# ============================================
MCP_HOST=localhost
MCP_PORT=8000

# ============================================
# Ollama Configuration
# ============================================
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=llama3.2:3b

# GPU Backend: auto, cuda, metal, cpu
# - auto: Auto-detect (tries CUDA first, then Metal, fallback to CPU)
# - cuda: Force NVIDIA CUDA (requires CUDA-capable GPU)
# - metal: Force Apple Metal (for Apple Silicon Macs)
# - cpu: Force CPU only (no GPU acceleration)
GPU_BACKEND=auto

# ============================================
# Embedding & Vector Search Configuration
# ============================================
# Provider: ollama (local, free) or openai (cloud, paid)
EMBEDDING_PROVIDER=ollama

# Model name (optional - auto-detected if not set)
# - For ollama: nomic-embed-text (768 dims, default)
# - For openai: text-embedding-3-small (1536 dims)
# EMBEDDING_MODEL=nomic-embed-text

# Chunk size for large documents (characters)
EMBEDDING_CHUNK_SIZE=1000

# Enable/disable automatic embedding generation on upload
EMBEDDING_ENABLED=true

# OpenAI API Key (only needed if EMBEDDING_PROVIDER=openai)
# OPENAI_API_KEY=sk-...

# ============================================
# Web UI Configuration
# ============================================
UI_HOST=localhost
UI_PORT=8501

# ============================================
# Logging Configuration
# ============================================
LOG_LEVEL=INFO
# LOG_FILE=/path/to/logfile.log

# ============================================
# Text Processing Configuration
# ============================================
MAX_TEXT_LENGTH=100000
CHUNK_SIZE=1000

# ============================================
# AI Model Configuration
# ============================================
TEMPERATURE=0.1
MAX_TOKENS=2000

# ============================================
# Caching Configuration
# ============================================
ENABLE_CACHE=true
CACHE_TTL=3600
TOKENIZERS_PARALLELISM=false

# ============================================
# Database Configuration
# ============================================
# MongoDB Atlas Configuration
# For local MongoDB: mongodb://localhost:27017
# For MongoDB Atlas: mongodb+srv://<username>:<password>@<cluster>.mongodb.net/?retryWrites=true&w=majority
MONGODB_URL=mongodb+srv://mcp_toolkit_user:54eahEzxCWw8GFB1@ai-mcp-toolkit.va8qnkw.mongodb.net/
MONGODB_DATABASE=ai_mcp_toolkit

# MongoDB Connection Pool Settings (optional)
MONGODB_MAX_POOL_SIZE=100
MONGODB_MIN_POOL_SIZE=10
MONGODB_MAX_IDLE_TIME_MS=30000

# Redis Configuration (optional - for caching)
# For local Redis: redis://localhost:6379
# For Redis Cloud: redis://<username>:<password>@<host>:<port>
REDIS_URL=redis://localhost:6379
REDIS_DB=0

# ============================================
# Security Configuration
# ============================================
ENABLE_CORS=true
CORS_ORIGINS=*

# ============================================
# Data Directory Configuration
# ============================================
DATA_DIR=~/.ai-mcp-toolkit
CACHE_DIR=~/.ai-mcp-toolkit/cache
MODELS_DIR=~/.ai-mcp-toolkit/models

# ============================================
# Development Configuration
# ============================================
# Uncomment for development mode
# DEBUG=true
# DEV_MODE=true
